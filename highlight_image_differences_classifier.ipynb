{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc1c75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference detector imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "from ipywidgets import *\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import io\n",
    "import pytesseract\n",
    "from pytesseract import Output as py_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bd21fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Imports\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "301e1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff detector\n",
    "MAX_FEATURES = 1000\n",
    "GOOD_MATCH_PERCENT = 0.5\n",
    "\n",
    "out_error = Output()\n",
    "\n",
    "def alignImages(im1, im2):\n",
    "    # Convert images to grayscale\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "    matches = list(matches)\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "#     cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "    \n",
    "    out_error.clear_output()\n",
    "    with out_error:\n",
    "        if len(points1)<4 or len(points2)<4:\n",
    "            print('The images are not similar enough for this POC, try other images please...')\n",
    "        else:\n",
    "            # Find homography\n",
    "            h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "            # Use homography\n",
    "            height, width, channels = im2.shape\n",
    "            im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "            return im1Reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "884e68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff detector\n",
    "btn1_upload = FileUpload(description='After. Img')\n",
    "btn2_upload = FileUpload(description='Before. Img')\n",
    "out_pl_ref = Output()\n",
    "out_pl_im = Output()\n",
    "btn_load = Button(description='Show Images')\n",
    "\n",
    "lbl_pred = widgets.Label()\n",
    "confidence_pred = widgets.Label()\n",
    "\n",
    "# Classifier\n",
    "path = Path()\n",
    "learn_inf = load_learner('mf_learner.pkl', cpu=True)\n",
    "\n",
    "rotation = -0\n",
    "\n",
    "def on_click_load(change):\n",
    "    imReference = Image.open(io.BytesIO(btn1_upload.data[-1]))\n",
    "    im = Image.open(io.BytesIO(btn2_upload.data[-1]))\n",
    "    out_pl_ref.clear_output()\n",
    "    out_pl_im.clear_output()\n",
    "    out_pl_diff.clear_output()\n",
    "    out_error.clear_output()\n",
    "    with out_pl_ref:\n",
    "        imReference.thumbnail([450,450])\n",
    "        display(imReference.rotate(rotation))\n",
    "    with out_pl_im:\n",
    "        im.thumbnail([450,450])\n",
    "        display(im.rotate(rotation))\n",
    "        \n",
    "btn_load.on_click(on_click_load)\n",
    "\n",
    "\n",
    "btn_diff = Button(description='Show Difference')\n",
    "out_pl_diff = Output()\n",
    "\n",
    "def on_click_find_diff(change):\n",
    "    try:\n",
    "        imReference = np.array(Image.open(io.BytesIO(btn1_upload.data[-1])))\n",
    "        im = np.array(Image.open(io.BytesIO(btn2_upload.data[-1])))\n",
    "\n",
    "        og_img = imReference.copy()\n",
    "\n",
    "        kernel = np.ones((6,6),np.uint8)\n",
    "        blur_kern = (7,7)\n",
    "\n",
    "        imReference = cv2.blur(imReference, blur_kern)\n",
    "        imReference = cv2.morphologyEx(imReference, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        im = cv2.blur(im, blur_kern)\n",
    "        im = cv2.morphologyEx(im, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        imReg = alignImages(im, imReference)\n",
    "\n",
    "    #     remove black borders from aligned image\n",
    "        black_border = np.where(imReg==0)\n",
    "        imRef_crop = imReference.copy()\n",
    "        imRef_crop[black_border]=0\n",
    "\n",
    "    #     find difference between images\n",
    "        diff = cv2.absdiff(imReg, imRef_crop)\n",
    "\n",
    "        out_pl_diff.clear_output()\n",
    "        with out_pl_diff:\n",
    "            result = (diff > 75) * diff\n",
    "\n",
    "            ##############\n",
    "            # Grayscale\n",
    "            gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "            edged = cv2.Canny(gray, 50, 200)\n",
    "            edged = cv2.dilate(edged, None, iterations=1)\n",
    "            edged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "            # Finding Contours\n",
    "            # Use a copy of the image e.g. edged.copy()\n",
    "            # since findContours alters the image\n",
    "            contours, hierarchy = cv2.findContours(edged, \n",
    "                cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            if len(contours)==0:\n",
    "                print(\"Error: please check the uploaded images...\")\n",
    "            else:\n",
    "                num_contours = min(5, len(contours)) # draw n biggest contours on image\n",
    "                similarity_score = np.zeros(num_contours)\n",
    "                for cont in range(num_contours):\n",
    "                    c = contours[cont]\n",
    "                    x,y,w,h = cv2.boundingRect(c)\n",
    "                    cv2.rectangle(og_img,(x,y),(x+w,y+h),(255,0,0),5) # red\n",
    "                    similarity_score[cont] = w*h\n",
    "\n",
    "                ################\n",
    "\n",
    "    #                 # show the black image with diff highlighted\n",
    "    #                 img2 = Image.fromarray(result)                \n",
    "    #                 img2.thumbnail([450,450])\n",
    "    #                 display(img2.rotate(rotation))\n",
    "\n",
    "                # show the images\n",
    "                img_contour = Image.fromarray(og_img) \n",
    "                img_contour.thumbnail([450,450])\n",
    "                display(img_contour.rotate(rotation))\n",
    "\n",
    "                size_of_image = np.shape(og_img)[0]*np.shape(og_img)[1]\n",
    "                size_of_contours = similarity_score.sum()\n",
    "                sim_score = size_of_contours/size_of_image*100\n",
    "\n",
    "                # print similarity score\n",
    "                print('Difference score: {:.1f}'.format(sim_score))\n",
    "\n",
    "    #                 classifier\n",
    "                img = PILImage.create(btn1_upload.data[-1])\n",
    "                pred,pred_idx,probs = learn_inf.predict(img)\n",
    "                if pred == 'Trench':\n",
    "                    pred = 'Not yet fully restored (untidy)...'\n",
    "                elif pred == 'Manhole':\n",
    "                    pred = 'Seems as though a manhole is present; making classification difficult...'\n",
    "                print(f'Prediction: {pred}; Probability: {probs[pred_idx]*100:.02f} %')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "btn_diff.on_click(on_click_find_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64ac74",
   "metadata": {},
   "source": [
    "# Reinstatement Difference Detector\n",
    "\n",
    "#### 1) Click on \"After. Img\" and select the final image after restoration\n",
    "#### 2) Click on \"Before. Img\" and select the reference or neat image to which we need to restore the premises\n",
    "#### 3) Click on \"Show Images\" to ensure the correct images have been selected\n",
    "#### 4) Click on \"Show Difference\" to see which areas of the \"After. Img\" selected in Step 1 vary from the \"Before. Img\"\n",
    "\n",
    "##### A difference score is also calculated. We can use this difference score to determine a pass/fail in future iterations\n",
    "\n",
    "##### Note: This algorithm has been optimized based on images received from MetroFibre access builds. Using this detector on images of a different nature does not guarantee accurate results. Further hyper-parameter tuning is required to use different picture types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31da8aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed09dff130548bf9125701a408aae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FileUpload(value={}, description='After. Img'), FileUpload(value={}, descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([HBox([btn1_upload, btn2_upload, btn_load, btn_diff]), \n",
    "      VBox([HBox([out_pl_ref, out_pl_im]), out_error, out_pl_diff])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59be3b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "PIL                 8.4.0\n",
       "cv2                 4.5.4-dev\n",
       "fastai              2.5.3\n",
       "fastcore            1.3.27\n",
       "fastprogress        0.2.7\n",
       "ipywidgets          7.6.5\n",
       "matplotlib          3.4.3\n",
       "numpy               1.21.2\n",
       "pandas              1.3.4\n",
       "pytesseract         0.3.8\n",
       "requests            2.26.0\n",
       "scipy               1.7.2\n",
       "session_info        1.0.0\n",
       "torch               1.10.0\n",
       "torchvision         0.11.1\n",
       "traitlets           5.1.1\n",
       "yaml                6.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "astunparse                  1.6.3\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "certifi                     2021.10.08\n",
       "cffi                        1.15.0\n",
       "charset_normalizer          2.0.7\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "fastdownload                0.0.5\n",
       "google                      NA\n",
       "idna                        3.3\n",
       "ipykernel                   6.5.0\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "joblib                      1.1.0\n",
       "kiwisolver                  1.3.2\n",
       "matplotlib_inline           NA\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "parso                       0.8.2\n",
       "pexpect                     4.8.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.22\n",
       "ptyprocess                  0.7.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyexpat                     NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   2.4.7\n",
       "pytz                        2021.3\n",
       "six                         1.16.0\n",
       "sklearn                     1.0.1\n",
       "storemagic                  NA\n",
       "threadpoolctl               3.0.0\n",
       "tornado                     6.1\n",
       "tqdm                        4.62.3\n",
       "typing_extensions           NA\n",
       "urllib3                     1.26.7\n",
       "wcwidth                     0.2.5\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      7.0.6\n",
       "jupyter_core        4.9.1\n",
       "notebook            6.4.5\n",
       "-----\n",
       "Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]\n",
       "Linux-5.13.0-27-generic-x86_64-with-glibc2.31\n",
       "-----\n",
       "Session information updated at 2022-01-27 12:41\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfca751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ba076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_env",
   "language": "python",
   "name": "fastai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
